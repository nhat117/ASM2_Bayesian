for (i in 1:Ntotal) {
zx[i, j] <- x[i, j] / xsd[j]  # Standardize predictors
}
}
}
model {
for (i in 1:Ntotal) {
# Likelihood for sale price
zy[i] ~ dnorm(mu[i], tau)
mu[i] <- zbeta0 + zbeta1 * zx[i, 1] + zbeta2 * zx[i, 2] + zbeta3 * zx[i, 3] + zbeta4 * zx[i, 4] + zbeta5 * zx[i, 5]
}
# Priors on standardized scale
zbeta0 ~ dnorm(0, 1/2^2)  # Intercept
zbeta1 ~ dnorm(90 / xsd[1], 1/(4/xsd[1]^2))  # Area
zbeta2 ~ dnorm(100000 / xsd[2], 1/4)  # Bedrooms
zbeta3 ~ dnorm(0, 1/4)  # Bathrooms
zbeta4 ~ dnorm(120000 / xsd[4], 1/(0.1/xsd[4]^2))  # Car Parks
zbeta5 ~ dnorm(-150000, 1/4)  # Property Type
# Prior for the variance (Inverse Gamma)
zVar ~ dgamma(0.01, 0.01)
tau <- 1 / zVar
# Transform to original scale
beta[1:Nx] <- (zbeta[1:Nx] / xsd[1:Nx]) * ysd
beta0 <- zbeta0 * ysd
# Predictions for new data
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i, 1] + beta[2] * xPred[i, 2] + beta[3] * xPred[i, 3] + beta[4] * xPred[i, 4] + beta[5] * xPred[i, 5]
}
# Model for independent variables based on distributions
for (i in 1:Ntotal) {
# Area follows a Gamma distribution
x[i, 1] ~ dgamma(alpha1, beta1)
# Bedrooms follow a Binomial distribution
x[i, 2] ~ dbin(p_bedrooms, n_bedrooms)
# Bathrooms follow a Binomial distribution
x[i, 3] ~ dbin(p_bathrooms, n_bathrooms)
# CarParks follow a Poisson distribution
x[i, 4] ~ dpois(lambda_carparks)
# PropertyType follows a Bernoulli distribution
x[i, 5] ~ dbern(p_propertytype)
}
# Hyperparameters
alpha1 <- 3; beta1 <- 1.5
p_bedrooms <- 0.5; n_bedrooms <- 6
p_bathrooms <- 0.5; n_bathrooms <- 4
lambda_carparks <- 1
p_propertytype <- 0.5
}
"
# Save the model to a file
writeLines(modelString, con = "BayesianModel.txt")
# Parameters to monitor
parameters <- c("zbeta0", "zbeta", "beta0", "beta", "tau", "zVar", "pred")
# MCMC settings
adaptSteps <- 500
burnInSteps <- 1000
nChains <- 3
thinSteps <- 5
numSavedSteps <- 5000
nIter <- ceiling((numSavedSteps * thinSteps) / nChains)
# Run the model using parallel processing
runJagsOut <- run.jags(
method = "parallel",
model = "BayesianModel.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE
)
# Load necessary libraries
graphics.off() # Close all graphics windows
rm(list=ls())  # Clear all existing data from memory
library(ggplot2)
library(ggpubr)
library(rjags)
library(runjags)
# Load utility functions
source("DBDA2E-utilities.R")
# Load the dataset
myData <- read.csv("Assignment2PropertyPrices.csv")
head(myData)
# Dependent Variable: Sale Price
y <- myData$SalePrice
# Independent Variables
x1 <- myData$Area         # Area (m²)
x2 <- myData$Bedrooms     # Number of Bedrooms
x3 <- myData$Bathrooms    # Number of Bathrooms
x4 <- myData$CarParks     # Number of Car Parks
x5 <- myData$PropertyType # Property Type (0: House, 1: Unit)
# Predictor matrix
x <- as.matrix(myData[, c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType")])
# Descriptive statistics
cat("\nCORRELATION MATRIX OF PREDICTORS:\n")
print(round(cor(x), 3))
# Prepare the new predictions
xPred <- matrix(c(400, 3, 2, 2, 0, 600, 4, 3, 3, 1), ncol = 5, byrow = TRUE)  # Example predictions
# Specify the data for JAGS
dataList <- list(
y = y,
x = x,
xPred = xPred,
Nx = ncol(x),
Ntotal = nrow(x),
Npred = nrow(xPred)
)
# Initial values for the MCMC chains
initsList <- list(
beta0 = 500000,  # Initial intercept
beta = c(90, 100000, 0, 120000, -150000),  # Initial guesses for the coefficients
Var = 120000000  # Initial value for variance
)
# JAGS model specification without scaling
modelString <- "
model {
for (i in 1:Ntotal) {
# Likelihood for sale price (Y follows a normal distribution)
y[i] ~ dnorm(mu[i], tau)
mu[i] <- beta0 + beta[1] * x[i, 1] + beta[2] * x[i, 2] + beta[3] * x[i, 3] + beta[4] * x[i, 4] + beta[5] * x[i, 5]
}
# Priors on the coefficients
beta0 ~ dnorm(0, 1.0E-6)  # Intercept
beta[1] ~ dnorm(90, 1.0E-2)  # Area (m²): Expert prior (90 AUD/m² increase)
beta[2] ~ dnorm(100000, 1.0E-6)  # Bedrooms: Weak prior (100,000 AUD/bedroom)
beta[3] ~ dnorm(0, 1.0E-6)  # Bathrooms: No expert knowledge
beta[4] ~ dnorm(120000, 1.0E-2)  # CarParks: Expert prior (120,000 AUD/car space)
beta[5] ~ dnorm(-150000, 1.0E-2)  # PropertyType: Strong prior (-150,000 AUD for units)
# Prior for the variance (Inverse Gamma)
Var ~ dgamma(0.01, 0.01)
tau <- 1 / Var
# Predictions for new data
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i, 1] + beta[2] * xPred[i, 2] + beta[3] * xPred[i, 3] + beta[4] * xPred[i, 4] + beta[5] * xPred[i, 5]
}
}
"
# Save the model to a file
writeLines(modelString, con = "BayesianModel_NoScaling.txt")
# Parameters to monitor
parameters <- c("beta0", "beta", "Var", "tau", "pred")
# MCMC settings
adaptSteps <- 500
burnInSteps <- 1000
nChains <- 3
thinSteps <- 5
numSavedSteps <- 5000
nIter <- ceiling((numSavedSteps * thinSteps) / nChains)
# Run the model using parallel processing
runJagsOut <- run.jags(
method = "parallel",
model = "BayesianModel_NoScaling.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE
)
# Convert results to MCMC list
codaSamples <- as.mcmc.list(runJagsOut)
# Thinning the MCMC chains (optional)
furtherThin <- 5
thinningSequence <- seq(1, nrow(codaSamples[[1]]), furtherThin)
newCodaSamples <- mcmc.list()
for (i in 1:nChains) {
newCodaSamples[[i]] <- as.mcmc(codaSamples[[i]][thinningSequence, ])
}
# Function to summarize MCMC results (smryMCMC_HD)
smryMCMC_HD <- function(codaSamples, compVal = NULL, saveName = NULL) {
summaryInfo <- NULL
mcmcMat <- as.matrix(codaSamples, chains = TRUE)
paramName <- colnames(mcmcMat)
for (pName in paramName) {
if (!is.null(compVal) && pName %in% colnames(compVal)) {
if (!is.na(compVal[pName])) {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName], compVal = as.numeric(compVal[pName])))
} else {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName]))
}
} else {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName]))
}
}
rownames(summaryInfo) <- paramName
if (!is.null(saveName)) {
write.csv(summaryInfo, file = paste(saveName, "SummaryInfo.csv", sep = ""))
}
return(summaryInfo)
}
# Function to plot MCMC results (plotMCMC_HD)
plotMCMC_HD <- function(codaSamples, data, xName = "x", yName = "y", showCurve = FALSE, compVal = NULL, saveName = NULL, saveType = "jpg") {
y <- data[, yName]
x <- as.matrix(data[, xName])
mcmcMat <- as.matrix(codaSamples, chains = TRUE)
beta0 <- mcmcMat[, "beta0"]
# Marginal histograms for beta0
histInfo <- plotPost(beta0, cex.lab = 1.75, showCurve = showCurve, xlab = bquote(beta[0]), main = "Intercept")
# Add more histograms for each beta
for (bIdx in 1:ncol(x)) {
histInfo <- plotPost(mcmcMat[, paste0("beta[", bIdx, "]")], cex.lab = 1.75, showCurve = showCurve, xlab = bquote(beta[.(bIdx)]), main = xName[bIdx])
}
}
# Summarize the results
compVal <- data.frame("beta0" = NA, "beta[1]" = NA, "beta[2]" = NA, "beta[3]" = NA, "beta[4]" = NA, "tau" = NA, check.names = FALSE)
summaryInfo <- smryMCMC_HD(codaSamples = codaSamples, compVal = compVal)
print(summaryInfo)
# Plot posterior distributions
plotMCMC_HD(codaSamples = codaSamples, data = myData, xName = c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType"), yName = "SalePrice", compVal = compVal)
# Predictive checks
coefficients <- summaryInfo[2:6, 3]  # Extract the model coefficients
Variance <- summaryInfo[7, 3]  # Extract the variance
meanPred <- as.matrix(cbind(rep(1, nrow(x)), x)) %*% as.vector(coefficients)
# Plot posterior distributions
plotMCMC_HD(codaSamples = codaSamples, data = myData, xName = c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType"), yName = "SalePrice", compVal = compVal)
# Load necessary libraries
graphics.off() # Close all graphics windows
rm(list=ls())  # Clear all existing data from memory
library(ggplot2)
library(ggpubr)
library(rjags)
library(runjags)
# Load utility functions
source("DBDA2E-utilities.R")
# Load the dataset
myData <- read.csv("Assignment2PropertyPrices.csv")
head(myData)
# Dependent Variable: Sale Price
y <- myData$SalePrice
# Independent Variables
x1 <- myData$Area         # Area (m²)
x2 <- myData$Bedrooms     # Number of Bedrooms
x3 <- myData$Bathrooms    # Number of Bathrooms
x4 <- myData$CarParks     # Number of Car Parks
x5 <- myData$PropertyType # Property Type (0: House, 1: Unit)
# Predictor matrix
x <- as.matrix(myData[, c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType")])
# Descriptive statistics
cat("\nCORRELATION MATRIX OF PREDICTORS:\n")
print(round(cor(x), 3))
# Prepare the new predictions
xPred <- matrix(c(400, 3, 2, 2, 0, 600, 4, 3, 3, 1), ncol = 5, byrow = TRUE)  # Example predictions
# Specify the data for JAGS
dataList <- list(
y = y,
x = x,
xPred = xPred,
Nx = ncol(x),
Ntotal = nrow(x),
Npred = nrow(xPred)
)
# Initial values for the MCMC chains
initsList <- list(
beta0 = 500000,  # Initial intercept
beta = c(90, 100000, 0, 120000, -150000),  # Initial guesses for the coefficients
Var = 120000000  # Initial value for variance
)
# JAGS model specification without scaling
modelString <- "
model {
for (i in 1:Ntotal) {
# Likelihood for sale price (Y follows a normal distribution)
y[i] ~ dnorm(mu[i], tau)
mu[i] <- beta0 + beta[1] * x[i, 1] + beta[2] * x[i, 2] + beta[3] * x[i, 3] + beta[4] * x[i, 4] + beta[5] * x[i, 5]
}
# Priors on the coefficients
beta0 ~ dnorm(0, 1.0E-6)  # Intercept
beta[1] ~ dnorm(90, 1.0E-2)  # Area (m²): Expert prior (90 AUD/m² increase)
beta[2] ~ dnorm(100000, 1.0E-6)  # Bedrooms: Weak prior (100,000 AUD/bedroom)
beta[3] ~ dnorm(0, 1.0E-6)  # Bathrooms: No expert knowledge
beta[4] ~ dnorm(120000, 1.0E-2)  # CarParks: Expert prior (120,000 AUD/car space)
beta[5] ~ dnorm(-150000, 1.0E-2)  # PropertyType: Strong prior (-150,000 AUD for units)
# Prior for the variance (Inverse Gamma)
Var ~ dgamma(0.01, 0.01)
tau <- 1 / Var
# Predictions for new data
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i, 1] + beta[2] * xPred[i, 2] + beta[3] * xPred[i, 3] + beta[4] * xPred[i, 4] + beta[5] * xPred[i, 5]
}
}
"
# Save the model to a file
writeLines(modelString, con = "BayesianModel_NoScaling.txt")
# Parameters to monitor
parameters <- c("beta0", "beta", "Var", "tau", "pred")
# MCMC settings
adaptSteps <- 500
burnInSteps <- 1000
nChains <- 3
thinSteps <- 5
numSavedSteps <- 5000
nIter <- ceiling((numSavedSteps * thinSteps) / nChains)
# Run the model using parallel processing
runJagsOut <- run.jags(
method = "parallel",
model = "BayesianModel_NoScaling.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE
)
# Convert results to MCMC list
codaSamples <- as.mcmc.list(runJagsOut)
# Thinning the MCMC chains (optional)
furtherThin <- 5
thinningSequence <- seq(1, nrow(codaSamples[[1]]), furtherThin)
newCodaSamples <- mcmc.list()
for (i in 1:nChains) {
newCodaSamples[[i]] <- as.mcmc(codaSamples[[i]][thinningSequence, ])
}
# Function to summarize MCMC results (smryMCMC_HD)
smryMCMC_HD <- function(codaSamples, compVal = NULL, saveName = NULL) {
summaryInfo <- NULL
mcmcMat <- as.matrix(codaSamples, chains = TRUE)
paramName <- colnames(mcmcMat)
for (pName in paramName) {
if (!is.null(compVal) && pName %in% colnames(compVal)) {
if (!is.na(compVal[pName])) {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName], compVal = as.numeric(compVal[pName])))
} else {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName]))
}
} else {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName]))
}
}
rownames(summaryInfo) <- paramName
if (!is.null(saveName)) {
write.csv(summaryInfo, file = paste(saveName, "SummaryInfo.csv", sep = ""))
}
return(summaryInfo)
}
# Function to plot MCMC results (plotMCMC_HD)
plotMCMC_HD <- function(codaSamples, data, xName = "x", yName = "y", showCurve = FALSE, compVal = NULL, saveName = NULL, saveType = "jpg") {
y <- data[, yName]
x <- as.matrix(data[, xName])
mcmcMat <- as.matrix(codaSamples, chains = TRUE)
beta0 <- mcmcMat[, "beta0"]
# Marginal histograms for beta0
histInfo <- plotPost(beta0, cex.lab = 1.75, showCurve = showCurve, xlab = bquote(beta[0]), main = "Intercept")
# Add more histograms for each beta
for (bIdx in 1:ncol(x)) {
histInfo <- plotPost(mcmcMat[, paste0("beta[", bIdx, "]")], cex.lab = 1.75, showCurve = showCurve, xlab = bquote(beta[.(bIdx)]), main = xName[bIdx])
}
}
# Summarize the results
compVal <- data.frame("beta0" = NA, "beta[1]" = NA, "beta[2]" = NA, "beta[3]" = NA, "beta[4]" = NA, "tau" = NA, check.names = FALSE)
summaryInfo <- smryMCMC_HD(codaSamples = codaSamples, compVal = compVal)
print(summaryInfo)
# Plot posterior distributions
plotMCMC_HD(codaSamples = codaSamples, data = myData, xName = c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType"), yName = "SalePrice", compVal = compVal)
# Load necessary libraries
graphics.off() # Close all graphics windows
rm(list=ls())  # Clear all existing data from memory
library(ggplot2)
library(ggpubr)
library(rjags)
library(runjags)
# Load utility functions
source("DBDA2E-utilities.R")
# Load the dataset
myData <- read.csv("Assignment2PropertyPrices.csv")
head(myData)
# Dependent Variable: Sale Price
y <- myData$SalePrice
# Independent Variables
x1 <- myData$Area         # Area (m²)
x2 <- myData$Bedrooms     # Number of Bedrooms
x3 <- myData$Bathrooms    # Number of Bathrooms
x4 <- myData$CarParks     # Number of Car Parks
x5 <- myData$PropertyType # Property Type (0: House, 1: Unit)
# Predictor matrix
x <- as.matrix(myData[, c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType")])
# Descriptive statistics
cat("\nCORRELATION MATRIX OF PREDICTORS:\n")
print(round(cor(x), 3))
# Prepare the new predictions
xPred <- matrix(c(400, 3, 2, 2, 0, 600, 4, 3, 3, 1), ncol = 5, byrow = TRUE)  # Example predictions
# Specify the data for JAGS
dataList <- list(
y = y,
x = x,
xPred = xPred,
Nx = ncol(x),
Ntotal = nrow(x),
Npred = nrow(xPred)
)
# Initial values for the MCMC chains
initsList <- list(
beta0 = 500000,  # Initial intercept
beta = c(90, 100000, 0, 120000, -150000),  # Initial guesses for the coefficients
Var = 120000000  # Initial value for variance
)
# JAGS model specification without scaling
modelString <- "
model {
for (i in 1:Ntotal) {
# Likelihood for sale price (Y follows a normal distribution)
y[i] ~ dnorm(mu[i], tau)
mu[i] <- beta0 + beta[1] * x[i, 1] + beta[2] * x[i, 2] + beta[3] * x[i, 3] + beta[4] * x[i, 4] + beta[5] * x[i, 5]
}
# Priors on the coefficients
beta0 ~ dnorm(0, 1.0E-6)  # Intercept
beta[1] ~ dnorm(90, 1.0E-2)  # Area (m²): Expert prior (90 AUD/m² increase)
beta[2] ~ dnorm(100000, 1.0E-6)  # Bedrooms: Weak prior (100,000 AUD/bedroom)
beta[3] ~ dnorm(0, 1.0E-6)  # Bathrooms: No expert knowledge
beta[4] ~ dnorm(120000, 1.0E-2)  # CarParks: Expert prior (120,000 AUD/car space)
beta[5] ~ dnorm(-150000, 1.0E-2)  # PropertyType: Strong prior (-150,000 AUD for units)
# Prior for the variance (Inverse Gamma)
Var ~ dgamma(0.01, 0.01)
tau <- 1 / Var
# Predictions for new data
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i, 1] + beta[2] * xPred[i, 2] + beta[3] * xPred[i, 3] + beta[4] * xPred[i, 4] + beta[5] * xPred[i, 5]
}
}
"
# Save the model to a file
writeLines(modelString, con = "BayesianModel_NoScaling.txt")
# Parameters to monitor
parameters <- c("beta0", "beta", "Var", "tau", "pred")
# MCMC settings
adaptSteps <- 500
burnInSteps <- 1000
nChains <- 3
thinSteps <- 5
numSavedSteps <- 5000
nIter <- ceiling((numSavedSteps * thinSteps) / nChains)
# Run the model using parallel processing
runJagsOut <- run.jags(
method = "parallel",
model = "BayesianModel_NoScaling.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE
)
# Convert results to MCMC list
codaSamples <- as.mcmc.list(runJagsOut)
# Thinning the MCMC chains (optional)
furtherThin <- 5
thinningSequence <- seq(1, nrow(codaSamples[[1]]), furtherThin)
newCodaSamples <- mcmc.list()
for (i in 1:nChains) {
newCodaSamples[[i]] <- as.mcmc(codaSamples[[i]][thinningSequence, ])
}
# Function to summarize MCMC results (smryMCMC_HD)
smryMCMC_HD <- function(codaSamples, compVal = NULL, saveName = NULL) {
summaryInfo <- NULL
mcmcMat <- as.matrix(codaSamples, chains = TRUE)
paramName <- colnames(mcmcMat)
for (pName in paramName) {
if (!is.null(compVal) && pName %in% colnames(compVal)) {
if (!is.na(compVal[pName])) {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName], compVal = as.numeric(compVal[pName])))
} else {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName]))
}
} else {
summaryInfo <- rbind(summaryInfo, summarizePost(mcmcMat[, pName]))
}
}
rownames(summaryInfo) <- paramName
if (!is.null(saveName)) {
write.csv(summaryInfo, file = paste(saveName, "SummaryInfo.csv", sep = ""))
}
return(summaryInfo)
}
# Function to plot MCMC results (plotMCMC_HD)
plotMCMC_HD <- function(codaSamples, data, xName = "x", yName = "y", showCurve = FALSE, compVal = NULL, saveName = NULL, saveType = "jpg") {
y <- data[, yName]
x <- as.matrix(data[, xName])
mcmcMat <- as.matrix(codaSamples, chains = TRUE)
beta0 <- mcmcMat[, "beta0"]
# Marginal histograms for beta0
# Set ylim manually if required
ylim_range <- range(codaSamples[, "beta0"], na.rm = TRUE, finite = TRUE)
xlim_range <- range(codaSamples[, "beta0"], na.rm = TRUE, finite = TRUE)
histInfo <- plotPost(beta0, cex.lab = 1.75, showCurve = showCurve, xlab = bquote(beta[0]), main = "Intercept", ylim = ylim_range, xlim = xlim_range)
# Add more histograms for each beta
for (bIdx in 1:ncol(x)) {
histInfo <- plotPost(mcmcMat[, paste0("beta[", bIdx, "]")], cex.lab = 1.75, showCurve = showCurve, xlab = bquote(beta[.(bIdx)]), main = xName[bIdx])
}
}
# Summarize the results
compVal <- data.frame("beta0" = NA, "beta[1]" = NA, "beta[2]" = NA, "beta[3]" = NA, "beta[4]" = NA, "tau" = NA, check.names = FALSE)
summaryInfo <- smryMCMC_HD(codaSamples = codaSamples, compVal = compVal)
print(summaryInfo)
# Plot posterior distributions
plotMCMC_HD(codaSamples = codaSamples, data = myData, xName = c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType"), yName = "SalePrice", compVal = compVal)
# Plot posterior distributions
plotMCMC_HD(codaSamples = codaSamples, data = myData, xName = c("Area", "Bedrooms", "Bathrooms", "CarParks", "PropertyType"), yName = "SalePrice", compVal = compVal)
