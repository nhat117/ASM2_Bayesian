return( summaryInfo )
}
#===============================================================================
# Include new prediction data
# Define the new prediction data (from the image you provided):
xPred <- array(NA, dim = c(5, 5))  # 5 properties with 5 predictors
# Populate the data (Area, Bedrooms, Bathrooms, CarParks, PropertyType)
xPred[1,] <- c(600, 2, 2, 1, 1)  # Property 1 (Unit)
xPred[2,] <- c(800, 3, 1, 2, 0)  # Property 2 (House)
xPred[3,] <- c(1500, 2, 1, 1, 0)  # Property 3 (House)
xPred[4,] <- c(2500, 5, 4, 4, 0)  # Property 4 (House)
xPred[5,] <- c(250, 3, 2, 1, 1)   # Property 5 (Unit)
# Prepare the data for JAGS
# Prepare the data for JAGS
# Assuming you have the property_data dataframe with 'SalePrice' as the target variable:
dataList <- list(
y = property_data$SalePrice,  # SalePrice is the target variable, ensure it's in 100k AUD
x = cbind(property_data$Area, property_data$Bedrooms, property_data$Bathrooms, property_data$CarParks, property_data$PropertyType),  # Predictors
Nx = 5,  # Number of predictors
Ntotal = nrow(property_data),  # Number of observations
xPred = xPred  # Prediction data for the new properties
)
# Initial values based on expert knowledge
initsList <- list(
zbeta0 = 2000,  # Intercept
zbeta = c(0.9, 1, 0, 1.2, -1.5),  # Expert knowledge for Area, Bedrooms, Bathrooms, CarParks, PropertyType
Var = 12000000  # Variance
)
# JAGS model string with priors scaled for 100k AUD units
modelString = "
data {
# Standardize the data
ym <- mean(y)
ysd <- sd(y)
for (i in 1:Ntotal) { zy[i] <- (y[i] - ym) / ysd }
for (j in 1:Nx) {
xm[j] <- mean(x[,j])
xsd[j] <- sd(x[,j])
for (i in 1:Ntotal) { zx[i,j] <- (x[i,j] - xm[j]) / xsd[j] }
}
# Expert priors (means and variances in original scale)
mu <- c(90, 100000, 100000, 120000, -150000)
Var <- c(10^2, 10^5, 10^5, 10^3, 10^4)
# Standardized prior means
muZ[1:Nx] <- mu[1:Nx] * xsd[1:Nx] / ysd
}
model {
for (i in 1:Ntotal) {
zy[i] ~ dt(zbeta0 + sum(zbeta[1:Nx] * zx[i,1:Nx]), 1/zsigma^2, nu)
}
# Priors for coefficients and intercept
zbeta0 ~ dnorm(0, 1/10^6)
for (j in 1:Nx) { zbeta[j] ~ dnorm(muZ[j], 1/Var[j]) }
zsigma ~ dunif(1.0E-5, 1.0E+5)
nu ~ dexp(1/30)
# Transform to original scale
beta[1:Nx] <- (zbeta[1:Nx] / xsd[1:Nx]) * ysd
beta0 <- zbeta0 * ysd + ym - sum(zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx]) * ysd
sigma <- zsigma * ysd
# Predictions for new properties
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i,1] + beta[2] * xPred[i,2] + beta[3] * xPred[i,3] + beta[4] * xPred[i,4] + beta[5] * xPred[i,5]
}
}
"
# Write the model to a file
writeLines(modelString, con="TEMPmodel.txt")
# Define the parameters to monitor
parameters <- c("zbeta0", "zbeta", "beta0", "beta", "tau", "zVar", "pred")
# MCMC settings
adaptSteps = 500       # Number of adaptation steps
burnInSteps = 1000     # Number of burn-in steps
nChains = 2            # Number of chains
thinSteps = 3          # Thinning parameter
numSavedSteps = 10000  # Number of saved MCMC steps
nIter = ceiling((numSavedSteps * thinSteps) / nChains)  # Total number of iterations per chain
# Run JAGS using the run.jags function
runJagsOut <- run.jags(method = "parallel",
model = "TEMPmodel.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE)
# Clear R's environment and close all graphics
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
# Load required libraries
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
# Load the necessary library
library(dplyr)
# Set the working directory#setwd("~/Documents/MATH2269_Bayesian/2024/presentations/Module 6/Application2")
source("DBDA2E-utilities.R")
property_data <- read.csv("./Assignment2PropertyPrices.csv")
set.seed(42)  # Setting a seed for reproducibility
property_data <- sample_n(property_data, 1000)
#===============PRELIMINARY FUNCTIONS FOR POSTERIOR INFERENCES====================
smryMCMC_HD = function(  codaSamples , compVal = NULL,  saveName=NULL) {
summaryInfo = NULL
mcmcMat = as.matrix(codaSamples,chains=TRUE)
paramName = colnames(mcmcMat)
for ( pName in paramName ) {
if (pName %in% colnames(compVal)){
if (!is.na(compVal[pName])) {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ,
compVal = as.numeric(compVal[pName]) ))
}
else {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ) )
}
} else {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ) )
}
}
rownames(summaryInfo) = paramName
if ( !is.null(saveName) ) {
write.csv( summaryInfo , file=paste(saveName,"SummaryInfo.csv",sep="") )
}
return( summaryInfo )
}
#===============================================================================
# Include new prediction data
# Define the new prediction data (from the image you provided):
xPred <- array(NA, dim = c(5, 5))  # 5 properties with 5 predictors
# Populate the data (Area, Bedrooms, Bathrooms, CarParks, PropertyType)
xPred[1,] <- c(600, 2, 2, 1, 1)  # Property 1 (Unit)
xPred[2,] <- c(800, 3, 1, 2, 0)  # Property 2 (House)
xPred[3,] <- c(1500, 2, 1, 1, 0)  # Property 3 (House)
xPred[4,] <- c(2500, 5, 4, 4, 0)  # Property 4 (House)
xPred[5,] <- c(250, 3, 2, 1, 1)   # Property 5 (Unit)
# Prepare the data for JAGS
# Prepare the data for JAGS
# Assuming you have the property_data dataframe with 'SalePrice' as the target variable:
# Assuming 'SalePrice' is the name of the column with sale prices
dataList <- list(
y = property_data$SalePrice,  # 'y' is the sale price (response variable)
x = cbind(
property_data$Area,        # Area of the property
property_data$Bedrooms,    # Number of bedrooms
property_data$Bathrooms,   # Number of bathrooms
property_data$CarParks,    # Number of car parks
property_data$PropertyType # Property type (0 for house, 1 for unit)
),
Nx = 5,  # Number of predictors
Ntotal = nrow(property_data),  # Number of observations in your dataset
xPred = matrix(               # Prediction data for new properties
c(600, 2, 2, 1, 1,
800, 3, 1, 2, 0,
1500, 2, 1, 1, 0,
2500, 5, 4, 4, 0,
250, 3, 2, 1, 1),
nrow = 5, byrow = TRUE
)
)
# Initial values based on expert knowledge
initsList <- list(
zbeta0 = 2000,  # Intercept
zbeta = c(0.9, 1, 0, 1.2, -1.5),  # Expert knowledge for Area, Bedrooms, Bathrooms, CarParks, PropertyType
Var = 12000000  # Variance
)
# JAGS model string with priors scaled for 100k AUD units
modelString = "
data {
# Standardize the data
ym <- mean(y)
ysd <- sd(y)
for (i in 1:Ntotal) { zy[i] <- (y[i] - ym) / ysd }
for (j in 1:Nx) {
xm[j] <- mean(x[,j])
xsd[j] <- sd(x[,j])
for (i in 1:Ntotal) { zx[i,j] <- (x[i,j] - xm[j]) / xsd[j] }
}
# Expert priors (means and variances in original scale)
mu <- c(90, 100000, 100000, 120000, -150000)
Var <- c(10^2, 10^5, 10^5, 10^3, 10^4)
# Standardized prior means
muZ[1:Nx] <- mu[1:Nx] * xsd[1:Nx] / ysd
}
model {
for (i in 1:Ntotal) {
zy[i] ~ dt(zbeta0 + sum(zbeta[1:Nx] * zx[i,1:Nx]), 1/zsigma^2, nu)
}
# Priors for coefficients and intercept
zbeta0 ~ dnorm(0, 1/10^6)
for (j in 1:Nx) { zbeta[j] ~ dnorm(muZ[j], 1/Var[j]) }
zsigma ~ dunif(1.0E-5, 1.0E+5)
nu ~ dexp(1/30)
# Transform to original scale
beta[1:Nx] <- (zbeta[1:Nx] / xsd[1:Nx]) * ysd
beta0 <- zbeta0 * ysd + ym - sum(zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx]) * ysd
sigma <- zsigma * ysd
# Predictions for new properties
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i,1] + beta[2] * xPred[i,2] + beta[3] * xPred[i,3] + beta[4] * xPred[i,4] + beta[5] * xPred[i,5]
}
}
"
# Write the model to a file
writeLines(modelString, con="TEMPmodel.txt")
# Define the parameters to monitor
parameters <- c("zbeta0", "zbeta", "beta0", "beta", "tau", "zVar", "pred")
# MCMC settings
adaptSteps = 500       # Number of adaptation steps
burnInSteps = 1000     # Number of burn-in steps
nChains = 2            # Number of chains
thinSteps = 3          # Thinning parameter
numSavedSteps = 10000  # Number of saved MCMC steps
nIter = ceiling((numSavedSteps * thinSteps) / nChains)  # Total number of iterations per chain
# Run JAGS using the run.jags function
runJagsOut <- run.jags(method = "parallel",
model = "TEMPmodel.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE)
# Clear R's environment and close all graphics
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
# Load required libraries
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
# Load the necessary library
library(dplyr)
# Set the working directory#setwd("~/Documents/MATH2269_Bayesian/2024/presentations/Module 6/Application2")
source("DBDA2E-utilities.R")
property_data <- read.csv("./Assignment2PropertyPrices.csv")
set.seed(42)  # Setting a seed for reproducibility
property_data <- sample_n(property_data, 1000)
#===============PRELIMINARY FUNCTIONS FOR POSTERIOR INFERENCES====================
smryMCMC_HD = function(  codaSamples , compVal = NULL,  saveName=NULL) {
summaryInfo = NULL
mcmcMat = as.matrix(codaSamples,chains=TRUE)
paramName = colnames(mcmcMat)
for ( pName in paramName ) {
if (pName %in% colnames(compVal)){
if (!is.na(compVal[pName])) {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ,
compVal = as.numeric(compVal[pName]) ))
}
else {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ) )
}
} else {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ) )
}
}
rownames(summaryInfo) = paramName
if ( !is.null(saveName) ) {
write.csv( summaryInfo , file=paste(saveName,"SummaryInfo.csv",sep="") )
}
return( summaryInfo )
}
#===============================================================================
# Include new prediction data
# Define the new prediction data (from the image you provided):
xPred <- array(NA, dim = c(5, 5))  # 5 properties with 5 predictors
# Populate the data (Area, Bedrooms, Bathrooms, CarParks, PropertyType)
xPred[1,] <- c(600, 2, 2, 1, 1)  # Property 1 (Unit)
xPred[2,] <- c(800, 3, 1, 2, 0)  # Property 2 (House)
xPred[3,] <- c(1500, 2, 1, 1, 0)  # Property 3 (House)
xPred[4,] <- c(2500, 5, 4, 4, 0)  # Property 4 (House)
xPred[5,] <- c(250, 3, 2, 1, 1)   # Property 5 (Unit)
# Prepare the data for JAGS
# Prepare the data for JAGS
# Assuming you have the property_data dataframe with 'SalePrice' as the target variable:
# Assuming 'SalePrice' is the name of the column with sale prices
dataList <- list(
y = property_data$SalePrice,  # 'y' is the sale price (response variable)
x = cbind(
property_data$Area,        # Area of the property
property_data$Bedrooms,    # Number of bedrooms
property_data$Bathrooms,   # Number of bathrooms
property_data$CarParks,    # Number of car parks
property_data$PropertyType # Property type (0 for house, 1 for unit)
),
Nx = 5,  # Number of predictors
Ntotal = nrow(property_data),  # Number of observations in your dataset
xPred = matrix(               # Prediction data for new properties
c(600, 2, 2, 1, 1,
800, 3, 1, 2, 0,
1500, 2, 1, 1, 0,
2500, 5, 4, 4, 0,
250, 3, 2, 1, 1),
nrow = 5, byrow = TRUE
)
)
# Initial values based on expert knowledge
initsList <- list(
zbeta0 = 2000,  # Intercept
zbeta = c(0.9, 1, 0, 1.2, -1.5),  # Expert knowledge for Area, Bedrooms, Bathrooms, CarParks, PropertyType
Var = 12000000  # Variance
)
# JAGS model string with priors scaled for 100k AUD units
modelString = "
data {
# Standardize the data
ym <- mean(y)
ysd <- sd(y)
for (i in 1:Ntotal) { zy[i] <- (y[i] - ym) / ysd }
for (j in 1:Nx) {
xm[j] <- mean(x[,j])
xsd[j] <- sd(x[,j])
for (i in 1:Ntotal) { zx[i,j] <- (x[i,j] - xm[j]) / xsd[j] }
}
# Expert priors (means and variances in original scale)
mu <- c(90, 100000, 100000, 120000, -150000)
Var <- c(10^2, 10^5, 10^5, 10^3, 10^4)
# Standardized prior means
muZ[1:Nx] <- mu[1:Nx] * xsd[1:Nx] / ysd
}
model {
for (i in 1:Ntotal) {
zy[i] ~ dt(zbeta0 + sum(zbeta[1:Nx] * zx[i,1:Nx]), 1/zsigma^2, nu)
}
# Priors for coefficients and intercept
zbeta0 ~ dnorm(0, 1/10^6)
for (j in 1:Nx) { zbeta[j] ~ dnorm(muZ[j], 1/Var[j]) }
zsigma ~ dunif(1.0E-5, 1.0E+5)
nu ~ dexp(1/30)
# Transform to original scale
beta[1:Nx] <- (zbeta[1:Nx] / xsd[1:Nx]) * ysd
beta0 <- zbeta0 * ysd + ym - sum(zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx]) * ysd
sigma <- zsigma * ysd
# Predictions for new properties
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i,1] + beta[2] * xPred[i,2] + beta[3] * xPred[i,3] + beta[4] * xPred[i,4] + beta[5] * xPred[i,5]
}
}
"
# Write the model to a file
writeLines(modelString, con="TEMPmodel.txt")
# Define the parameters to monitor
parameters <- c("zbeta0", "zbeta", "beta0", "beta", "tau", "zVar", "pred")
# MCMC settings
adaptSteps = 500       # Number of adaptation steps
burnInSteps = 1000     # Number of burn-in steps
nChains = 2            # Number of chains
thinSteps = 3          # Thinning parameter
numSavedSteps = 10000  # Number of saved MCMC steps
nIter = ceiling((numSavedSteps * thinSteps) / nChains)  # Total number of iterations per chain
# Run JAGS using the run.jags function
runJagsOut <- run.jags(method = "parallel",
model = "TEMPmodel.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE)
# Clear R's environment and close all graphics
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
# Load required libraries
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
# Load the necessary library
library(dplyr)
# Set the working directory#setwd("~/Documents/MATH2269_Bayesian/2024/presentations/Module 6/Application2")
source("DBDA2E-utilities.R")
property_data <- read.csv("./Assignment2PropertyPrices.csv")
set.seed(42)  # Setting a seed for reproducibility
property_data <- sample_n(property_data, 1000)
#===============PRELIMINARY FUNCTIONS FOR POSTERIOR INFERENCES====================
smryMCMC_HD = function(  codaSamples , compVal = NULL,  saveName=NULL) {
summaryInfo = NULL
mcmcMat = as.matrix(codaSamples,chains=TRUE)
paramName = colnames(mcmcMat)
for ( pName in paramName ) {
if (pName %in% colnames(compVal)){
if (!is.na(compVal[pName])) {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ,
compVal = as.numeric(compVal[pName]) ))
}
else {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ) )
}
} else {
summaryInfo = rbind( summaryInfo , summarizePost( paramSampleVec = mcmcMat[,pName] ) )
}
}
rownames(summaryInfo) = paramName
if ( !is.null(saveName) ) {
write.csv( summaryInfo , file=paste(saveName,"SummaryInfo.csv",sep="") )
}
return( summaryInfo )
}
#===============================================================================
# Include new prediction data
# Define the new prediction data (from the image you provided):
xPred <- array(NA, dim = c(5, 5))  # 5 properties with 5 predictors
# Populate the data (Area, Bedrooms, Bathrooms, CarParks, PropertyType)
xPred[1,] <- c(600, 2, 2, 1, 1)  # Property 1 (Unit)
xPred[2,] <- c(800, 3, 1, 2, 0)  # Property 2 (House)
xPred[3,] <- c(1500, 2, 1, 1, 0)  # Property 3 (House)
xPred[4,] <- c(2500, 5, 4, 4, 0)  # Property 4 (House)
xPred[5,] <- c(250, 3, 2, 1, 1)   # Property 5 (Unit)
# Prepare the data for JAGS
# Prepare the data for JAGS
# Assuming you have the property_data dataframe with 'SalePrice' as the target variable:
# Assuming 'SalePrice' is the name of the column with sale prices
dataList <- list(
y = property_data$SalePrice,  # 'y' is the sale price (response variable)
x = cbind(
property_data$Area,        # Area of the property
property_data$Bedrooms,    # Number of bedrooms
property_data$Bathrooms,   # Number of bathrooms
property_data$CarParks,    # Number of car parks
property_data$PropertyType # Property type (0 for house, 1 for unit)
),
Nx = 5,  # Number of predictors
Ntotal = nrow(property_data),  # Number of observations in your dataset
xPred = matrix(               # Prediction data for new properties
c(600, 2, 2, 1, 1,
800, 3, 1, 2, 0,
1500, 2, 1, 1, 0,
2500, 5, 4, 4, 0,
250, 3, 2, 1, 1),
nrow = 5, byrow = TRUE
)
)
# Initial values based on expert knowledge
initsList <- list(
zbeta0 = 2000,  # Intercept
zbeta = c(0.9, 1, 0, 1.2, -1.5),  # Expert knowledge for Area, Bedrooms, Bathrooms, CarParks, PropertyType
Var = 12000000  # Variance
)
# JAGS model string with priors scaled for 100k AUD units
modelString = "
data {
# Standardize the data
ym <- mean(y)
ysd <- sd(y)
for (i in 1:Ntotal) { zy[i] <- (y[i] - ym) / ysd }
for (j in 1:Nx) {
xm[j] <- mean(x[,j])
xsd[j] <- sd(x[,j])
for (i in 1:Ntotal) { zx[i,j] <- (x[i,j] - xm[j]) / xsd[j] }
}
# Expert priors (means and variances in original scale)
mu <- c(90, 100000, 100000, 120000, -150000)
Var <- c(10^2, 10^5, 10^5, 10^3, 10^4)
# Standardized prior means
muZ[1:Nx] <- mu[1:Nx] * xsd[1:Nx] / ysd
}
model {
for (i in 1:Ntotal) {
zy[i] ~ dt(zbeta0 + sum(zbeta[1:Nx] * zx[i,1:Nx]), 1/zsigma^2, nu)
}
# Priors for coefficients and intercept
zbeta0 ~ dnorm(0, 1/10^6)
for (j in 1:Nx) { zbeta[j] ~ dnorm(muZ[j], 1/Var[j]) }
zsigma ~ dunif(1.0E-5, 1.0E+5)
nu ~ dexp(1/30)
# Transform to original scale
beta[1:Nx] <- (zbeta[1:Nx] / xsd[1:Nx]) * ysd
beta0 <- zbeta0 * ysd + ym - sum(zbeta[1:Nx] * xm[1:Nx] / xsd[1:Nx]) * ysd
sigma <- zsigma * ysd
# Predictions for new properties
for (i in 1:Npred) {
pred[i] <- beta0 + beta[1] * xPred[i,1] + beta[2] * xPred[i,2] + beta[3] * xPred[i,3] + beta[4] * xPred[i,4] + beta[5] * xPred[i,5]
}
}
"
# Write the model to a file
writeLines(modelString, con="TEMPmodel.txt")
# Define the parameters to monitor
parameters <- c("zbeta0", "zbeta", "beta0", "beta", "tau", "zVar", "pred")
# MCMC settings
adaptSteps = 500       # Number of adaptation steps
burnInSteps = 1000     # Number of burn-in steps
nChains = 2            # Number of chains
thinSteps = 3          # Thinning parameter
numSavedSteps = 10000  # Number of saved MCMC steps
nIter = ceiling((numSavedSteps * thinSteps) / nChains)  # Total number of iterations per chain
# Run JAGS using the run.jags function
runJagsOut <- run.jags(method = "parallel",
model = "TEMPmodel.txt",
monitor = parameters,
data = dataList,
inits = initsList,
n.chains = nChains,
adapt = adaptSteps,
burnin = burnInSteps,
sample = numSavedSteps,
thin = thinSteps,
summarise = FALSE,
plots = FALSE)
